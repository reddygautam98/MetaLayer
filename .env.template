# MetaLayer Production Environment Configuration Template
# Copy this file to .env and update with your actual values
# DO NOT COMMIT THE .env FILE TO VERSION CONTROL

# ===========================================
# DATABASE CONFIGURATION
# ===========================================
# PostgreSQL Database Credentials
POSTGRES_PASSWORD=YOUR_SECURE_PASSWORD_HERE_CHANGE_ME
POSTGRES_USER=postgres
POSTGRES_DB=airflow
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# Database Connection URL (constructed from above)
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:${POSTGRES_PASSWORD}@postgres:5432/airflow

# ===========================================
# AIRFLOW SECURITY CONFIGURATION  
# ===========================================
# Airflow Secret Key (generate a secure random string)
AIRFLOW_SECRET_KEY=YOUR_SECURE_SECRET_KEY_HERE_CHANGE_ME

# Airflow Admin Credentials
AIRFLOW_ADMIN_USERNAME=admin
AIRFLOW_ADMIN_PASSWORD=YOUR_ADMIN_PASSWORD_HERE_CHANGE_ME
AIRFLOW_ADMIN_EMAIL=admin@yourdomain.com

# ===========================================
# DATA QUALITY CONFIGURATION
# ===========================================
# Enable comprehensive data quality validation
DATA_QUALITY_ENABLED=true

# Maximum allowed record errors per batch
MAX_RECORD_ERRORS=1000

# Maximum allowed data loss percentage (5% = 0.05)
DATA_VALIDATION_THRESHOLD=0.05

# Enable comprehensive audit logging
AUDIT_LOGGING_ENABLED=true

# Enable business rule validation
BUSINESS_VALIDATION_ENABLED=true

# ===========================================
# PERFORMANCE CONFIGURATION
# ===========================================
# Airflow Performance Settings
AIRFLOW__CORE__PARALLELISM=64
AIRFLOW__CORE__DAG_CONCURRENCY=32
AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=8
AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG=16

# Batch sizes for processing
BRONZE_LAYER_BATCH_SIZE=10000
SILVER_LAYER_BATCH_SIZE=5000

# Airflow Performance Settings
AIRFLOW__CORE__PARALLELISM=16
AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG=8
AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=1

# Database Pool Settings
AIRFLOW__DATABASE__SQL_ALCHEMY_POOL_SIZE=10
AIRFLOW__DATABASE__SQL_ALCHEMY_MAX_OVERFLOW=20

# ===========================================
# MONITORING & ALERTING
# ===========================================
# Enable email alerts for DAG failures
EMAIL_ALERTS_ENABLED=true
ALERT_EMAIL_RECIPIENTS=data-team@yourdomain.com

# Enable performance monitoring
PERFORMANCE_MONITORING_ENABLED=true

# Slack webhook for alerts (optional)
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK

# ===========================================
# SECURITY & COMPLIANCE
# ===========================================
# Enable encryption for sensitive data
DATA_ENCRYPTION_ENABLED=true
ENCRYPTION_KEY=YOUR_32_BYTE_ENCRYPTION_KEY_HERE

# Enable access logging
ACCESS_LOGGING_ENABLED=true

# Data retention policies (in days)
RAW_DATA_RETENTION_DAYS=90
PROCESSED_DATA_RETENTION_DAYS=365
LOG_RETENTION_DAYS=30

# ===========================================
# EXTERNAL INTEGRATIONS
# ===========================================
# Cloud storage configuration (if using)
# AWS_ACCESS_KEY_ID=your_aws_access_key
# AWS_SECRET_ACCESS_KEY=your_aws_secret_key  
# AWS_DEFAULT_REGION=us-east-1
# S3_BUCKET_NAME=metalayer-data-bucket

# Azure configuration (if using)
# AZURE_STORAGE_ACCOUNT_NAME=your_storage_account
# AZURE_STORAGE_ACCOUNT_KEY=your_storage_key
# AZURE_CONTAINER_NAME=metalayer-data

# ===========================================
# DEVELOPMENT/STAGING OVERRIDES
# ===========================================
# Set to 'development', 'staging', or 'production'
ENVIRONMENT=production

# Enable debug logging in non-production
AIRFLOW__LOGGING__LOGGING_LEVEL=INFO

# ===========================================
# MONITORING & OBSERVABILITY
# ===========================================
# Grafana Admin Credentials
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=YOUR_GRAFANA_PASSWORD_HERE_CHANGE_ME

# Prometheus Settings
PROMETHEUS_RETENTION_TIME=200h
PROMETHEUS_STORAGE_PATH=/prometheus

# Enable metrics collection
AIRFLOW__METRICS__STATSD_ON=true
AIRFLOW__METRICS__STATSD_HOST=localhost
AIRFLOW__METRICS__STATSD_PORT=8125
AIRFLOW__METRICS__STATSD_PREFIX=metalayer

# Enable Prometheus metrics
PROMETHEUS_METRICS_ENABLED=true

# ===========================================
# BACKUP & DISASTER RECOVERY
# ===========================================
# Backup Configuration
BACKUP_RETENTION_DAYS=30
BACKUP_DIRECTORY=C:\MetaLayer\Backups
BACKUP_SCHEDULE_CRON="0 2 * * *"  # Daily at 2 AM

# Enable backup encryption
BACKUP_ENCRYPTION_ENABLED=true
BACKUP_ENCRYPTION_KEY=YOUR_BACKUP_ENCRYPTION_KEY_HERE_CHANGE_ME

# ===========================================
# RESOURCE LIMITS (Docker)
# ===========================================
# CPU and Memory limits (used by docker-compose)
WEBSERVER_CPU_LIMIT=2.0
WEBSERVER_MEMORY_LIMIT=4G
SCHEDULER_CPU_LIMIT=2.0
SCHEDULER_MEMORY_LIMIT=4G
POSTGRES_CPU_LIMIT=1.0
POSTGRES_MEMORY_LIMIT=2G

# Load example DAGs (set to false in production)
AIRFLOW__CORE__LOAD_EXAMPLES=false

# Pause DAGs at creation (recommended for production)
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true