# MetaLayer CI/CD Pipeline
# Complete workflow for testing, building, and deploying the MetaLayer data pipeline

name: üöÄ MetaLayer CI/CD Pipeline

on:
  push:
    branches: [ main, develop, staging ]
  pull_request:
    branches: [ main, develop ]
    types: [ opened, synchronize, reopened ]
  release:
    types: [ published ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment Environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - development
        - staging
        - production
      deploy_monitoring:
        description: 'Deploy Monitoring Stack'
        required: false
        default: true
        type: boolean

permissions:
  actions: read
  contents: read
  security-events: write
  packages: write

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}/metalayer
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1

jobs:
  # ==============================================================================
  # CODE QUALITY & SECURITY
  # ==============================================================================
  code-quality:
    name: üîç Code Quality & Security
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: üìÇ Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: üêç Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: üì¶ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install flake8 black isort bandit safety pytest pytest-cov
        
    - name: üé® Code Formatting Check
      run: |
        echo "Checking code formatting with Black..."
        black --check --diff --exclude "\.venv|__pycache__|\.git|node_modules" dags/ include/ tests/
        
    - name: üìè Import Sorting Check
      run: |
        echo "Checking import sorting with isort..."
        isort --check-only --diff dags/ include/ tests/
        
    - name: üîç Linting with Flake8
      run: |
        echo "Running Flake8 linting..."
        flake8 dags/ include/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 dags/ include/ tests/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        
    - name: üõ°Ô∏è Security Analysis with Bandit
      run: |
        echo "Running security analysis..."
        bandit -r dags/ include/ -f json -o bandit-report.json || true
        bandit -r dags/ include/ -ll
        
    - name: üîí Dependency Security Check
      run: |
        echo "Checking for known security vulnerabilities..."
        safety check --json > safety-report.json || true
        safety check
        
    - name: üìä Upload Security Reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
        retention-days: 30

  # ==============================================================================
  # AIRFLOW DAG VALIDATION
  # ==============================================================================
  dag-validation:
    name: ‚úÖ DAG Validation
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_PASSWORD: airflow
          POSTGRES_USER: airflow
          POSTGRES_DB: airflow
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - name: üìÇ Checkout Repository
      uses: actions/checkout@v4
      
    - name: üêç Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: üì¶ Install Airflow Dependencies
      run: |
        python -m pip install --upgrade pip
        
        # Install Airflow with postgres extras and constraints for stability
        AIRFLOW_VERSION=2.8.0
        PYTHON_VERSION=3.11
        CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"
        
        pip install "apache-airflow[postgres]==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"
        
        # Ensure Flask-Session is present for airflow.web.session import
        pip install "Flask-Session>=0.4.0"
        
        # Ensure psycopg2 is available for database connections
        pip install "psycopg2-binary==2.9.7"
        
        # Install project dependencies
        pip install -r requirements.txt

    - name: ‚úÖ Verify Flask-Session & Airflow Import
      run: |
        echo "üîç Verifying required packages are installed..."
        python -c "import flask_session; print('‚úÖ flask_session module available')"
        python -c "import airflow; print('‚úÖ airflow version:', airflow.__version__)"
        python -c "from airflow.web.session import AirflowSessionInterface; print('‚úÖ airflow.web.session import successful')"
        python -c "import psycopg2; print('‚úÖ psycopg2 module available, version:', psycopg2.__version__)"
        python -c "from psycopg2.extras import RealDictCursor; print('‚úÖ psycopg2.extras import successful')"
        echo "üéâ All required modules verified successfully!"
        
    - name: üîß Initialize Airflow
      run: |
        export AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@localhost:5432/airflow
        export AIRFLOW__CORE__LOAD_EXAMPLES=false
        export AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
        airflow db init
        
    - name: ‚úÖ Validate DAG Files
      run: |
        export AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@localhost:5432/airflow
        export PYTHONPATH="${PYTHONPATH}:${GITHUB_WORKSPACE}/include"
        
        echo "Listing all DAG files..."
        find dags/ -name "*.py" -not -path "*/disabled_dags/*" -not -path "*/__pycache__/*"
        
        echo "Validating DAG syntax..."
        python -m py_compile dags/*.py
        
        echo "Testing DAG imports..."
        for dag_file in dags/*.py; do
          if [[ "$dag_file" != *"disabled_dags"* && "$dag_file" != *"__pycache__"* ]]; then
            echo "Testing $dag_file"
            python -c "import sys; sys.path.insert(0, 'include'); exec(open('$dag_file').read())"
          fi
        done
        
        echo "Running Airflow DAG validation..."
        airflow dags list
        
    - name: üß™ Run DAG Tests
      run: |
        export AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@localhost:5432/airflow
        export PYTHONPATH="${PYTHONPATH}:${GITHUB_WORKSPACE}/include"
        
        if [ -d "tests/dags" ]; then
          python -m pytest tests/dags/ -v --tb=short
        fi

  # ==============================================================================
  # BUILD & PUSH DOCKER IMAGES
  # ==============================================================================
  build-images:
    name: üèóÔ∏è Build & Push Images
    runs-on: ubuntu-latest
    needs: [ code-quality, dag-validation ]
    if: github.event_name != 'pull_request'
    timeout-minutes: 30
    
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
    
    steps:
    - name: üìÇ Checkout Repository
      uses: actions/checkout@v4
      
    - name: üîß Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: üîë Login to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
        
    - name: üè∑Ô∏è Extract Metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
        labels: |
          org.opencontainers.image.title=MetaLayer
          org.opencontainers.image.description=Production-ready data pipeline with Airflow
          org.opencontainers.image.vendor=${{ github.repository_owner }}
          
    - name: üèóÔ∏è Build and Push Image
      id: build
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        build-args: |
          BUILDKIT_INLINE_CACHE=1
          
    - name: üõ°Ô∏è Scan Image for Vulnerabilities
      uses: anchore/scan-action@v3
      id: scan
      with:
        image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
        fail-build: false
        severity-cutoff: high
        
    - name: üìä Upload Vulnerability Report
      uses: github/codeql-action/upload-sarif@v3
      if: always() && steps.scan.outputs.sarif != ''
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}

  # ==============================================================================
  # DEPLOY TO ENVIRONMENTS
  # ==============================================================================
  deploy-staging:
    name: üöÄ Deploy to Staging
    runs-on: ubuntu-latest
    needs: [ build-images ]
    if: github.ref == 'refs/heads/develop' || github.event_name == 'workflow_dispatch'
    environment: staging
    timeout-minutes: 20
    
    steps:
    - name: üìÇ Checkout Repository
      uses: actions/checkout@v4
      
    - name: üîß Setup Environment Variables
      run: |
        echo "ENVIRONMENT=staging" >> $GITHUB_ENV
        echo "IMAGE_TAG=${{ needs.build-images.outputs.image-tag }}" >> $GITHUB_ENV
        echo "POSTGRES_PASSWORD=${{ secrets.STAGING_POSTGRES_PASSWORD }}" >> $GITHUB_ENV
        echo "AIRFLOW_ADMIN_PASSWORD=${{ secrets.STAGING_AIRFLOW_PASSWORD }}" >> $GITHUB_ENV
        
    - name: üê≥ Deploy with Docker Compose
      run: |
        # Create environment-specific override
        envsubst < docker-compose.override.yml > docker-compose.staging.yml
        
        # Deploy the stack
        docker compose -f docker-compose.yml -f docker-compose.staging.yml up -d
        
        # Wait for services to be healthy
        timeout 300 bash -c 'until docker compose ps | grep -q "healthy"; do sleep 10; done'
        
    - name: üß™ Health Checks
      run: |
        echo "Running health checks..."
        
        # Check Airflow webserver
        curl -f http://localhost:8080/health || exit 1
        
        # Check PostgreSQL
        docker compose exec -T postgres pg_isready -U postgres || exit 1
        
        # Check Prometheus
        curl -f http://localhost:9090/-/healthy || exit 1
        
        # Check Grafana
        curl -f http://localhost:3000/api/health || exit 1
        
        echo "All services are healthy!"
        
    - name: üîç Verify DAGs
      run: |
        echo "Verifying DAG deployment..."
        
        # Wait for DAGs to be loaded
        sleep 30
        
        # Check if DAGs are loaded correctly
        docker compose exec -T webserver airflow dags list
        
        # Verify specific DAGs exist
        docker compose exec -T webserver airflow dags show bronze_layer_production
        docker compose exec -T webserver airflow dags show silver_layer_production
        docker compose exec -T webserver airflow dags show gold_layer_production

  deploy-production:
    name: üéØ Deploy to Production
    runs-on: ubuntu-latest
    needs: [ build-images ]
    if: github.ref == 'refs/heads/main' || github.event.release.target_commitish == 'main'
    environment: production
    timeout-minutes: 30
    
    steps:
    - name: üìÇ Checkout Repository
      uses: actions/checkout@v4
      
    - name: üîß Setup Production Environment
      run: |
        echo "ENVIRONMENT=production" >> $GITHUB_ENV
        echo "IMAGE_TAG=${{ needs.build-images.outputs.image-tag }}" >> $GITHUB_ENV
        echo "POSTGRES_PASSWORD=${{ secrets.PROD_POSTGRES_PASSWORD }}" >> $GITHUB_ENV
        echo "AIRFLOW_ADMIN_PASSWORD=${{ secrets.PROD_AIRFLOW_PASSWORD }}" >> $GITHUB_ENV
        
    - name: üõ°Ô∏è Security Pre-deployment Checks
      run: |
        echo "Running security pre-deployment checks..."
        
        # Verify secrets are set
        [ -n "${{ secrets.PROD_POSTGRES_PASSWORD }}" ] || { echo "Missing PROD_POSTGRES_PASSWORD"; exit 1; }
        [ -n "${{ secrets.PROD_AIRFLOW_PASSWORD }}" ] || { echo "Missing PROD_AIRFLOW_PASSWORD"; exit 1; }
        
        # Check for security configurations
        grep -q "GF_SECURITY_ADMIN_PASSWORD" docker-compose.override.yml || { echo "Missing Grafana admin password"; exit 1; }
        
        echo "Security checks passed!"
        
    - name: üì¶ Backup Current State
      run: |
        echo "Creating backup of current state..."
        
        # Backup database if it exists
        if docker compose ps postgres | grep -q "Up"; then
          docker compose exec -T postgres pg_dump -U postgres airflow > backup_$(date +%Y%m%d_%H%M%S).sql
        fi
        
        # Backup Grafana dashboards
        if docker compose ps grafana | grep -q "Up"; then
          docker compose exec -T grafana tar -czf - /var/lib/grafana > grafana_backup_$(date +%Y%m%d_%H%M%S).tar.gz
        fi
        
    - name: üöÄ Production Deployment
      run: |
        echo "Deploying to production..."
        
        # Create production-specific configuration
        envsubst < docker-compose.override.yml > docker-compose.production.yml
        
        # Deploy with blue-green strategy
        docker compose -f docker-compose.yml -f docker-compose.production.yml up -d --wait
        
        # Wait for all services to be healthy
        timeout 600 bash -c 'until [ $(docker compose ps --filter "status=running" | grep "healthy" | wc -l) -ge 6 ]; do sleep 15; done'
        
    - name: üîç Production Health Verification
      run: |
        echo "Verifying production deployment..."
        
        # Comprehensive health checks
        services=("webserver:8080" "postgres:5432" "prometheus:9090" "grafana:3000")
        
        for service in "${services[@]}"; do
          IFS=':' read -r name port <<< "$service"
          echo "Checking $name on port $port..."
          
          case $name in
            "webserver")
              curl -f http://localhost:$port/health || exit 1
              ;;
            "postgres")
              docker compose exec -T postgres pg_isready -U postgres || exit 1
              ;;
            "prometheus")
              curl -f http://localhost:$port/-/healthy || exit 1
              ;;
            "grafana")
              curl -f http://localhost:$port/api/health || exit 1
              ;;
          esac
          
          echo "$name is healthy ‚úÖ"
        done
        
        echo "Production deployment verified successfully! üéâ"

  # ==============================================================================
  # MONITORING & NOTIFICATIONS
  # ==============================================================================
  notify-deployment:
    name: üì¢ Deployment Notifications
    runs-on: ubuntu-latest
    needs: [ deploy-staging, deploy-production ]
    if: always()
    
    steps:
    - name: üìß Notify Success
      if: needs.deploy-staging.result == 'success' || needs.deploy-production.result == 'success'
      run: |
        echo "Deployment completed successfully! üéâ"
        echo "Environment: ${{ github.ref }}"
        echo "Commit: ${{ github.sha }}"
        echo "Actor: ${{ github.actor }}"
        
    - name: üö® Notify Failure
      if: needs.deploy-staging.result == 'failure' || needs.deploy-production.result == 'failure'
      run: |
        echo "Deployment failed! ‚ùå"
        echo "Please check the logs and take appropriate action."
        exit 1

  # ==============================================================================
  # CLEANUP
  # ==============================================================================
  cleanup:
    name: üßπ Cleanup
    runs-on: ubuntu-latest
    needs: [ deploy-staging, deploy-production ]
    if: always()
    
    steps:
    - name: üóëÔ∏è Clean up old images
      run: |
        echo "Cleaning up old container images..."
        docker image prune -f --filter "until=72h"
        
    - name: üìä Deployment Summary
      run: |
        echo "## üöÄ MetaLayer Deployment Summary" >> $GITHUB_STEP_SUMMARY
        echo "| Service | Status | Environment |" >> $GITHUB_STEP_SUMMARY
        echo "|---------|--------|-------------|" >> $GITHUB_STEP_SUMMARY
        echo "| Code Quality | ‚úÖ | All |" >> $GITHUB_STEP_SUMMARY
        echo "| DAG Validation | ‚úÖ | All |" >> $GITHUB_STEP_SUMMARY
        echo "| Image Build | ‚úÖ | All |" >> $GITHUB_STEP_SUMMARY
        echo "| Staging Deploy | ${{ needs.deploy-staging.result == 'success' && '‚úÖ' || '‚ùå' }} | Staging |" >> $GITHUB_STEP_SUMMARY
        echo "| Production Deploy | ${{ needs.deploy-production.result == 'success' && '‚úÖ' || '‚ùå' }} | Production |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Deployment Time:** $(date)" >> $GITHUB_STEP_SUMMARY
        echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "**Triggered by:** ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY