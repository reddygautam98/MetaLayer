#!/usr/bin/env python3
"""
MetaLayer Data Quality and Utility Function Tester
Tests all utility functions and data quality monitoring capabilities
"""

import sys
import traceback
from pathlib import Path


def test_utility_imports():
    """Test importing all utility modules"""
    print("üîç Testing Utility Function Imports...")

    results = []
    utility_modules = [
        "include.utils.data_quality_monitoring",
        "include.utils.metrics_exporter",
        "include.utils.connection_pooling",
        "include.utils.incremental_processing",
    ]

    # Add include directory to Python path
    import sys

    sys.path.append("include")

    for module_name in utility_modules:
        try:
            # Try to import the module
            module = __import__(module_name, fromlist=[""])
            results.append(f"‚úÖ {module_name} - Imported successfully")

            # Try to access key functions if available
            if hasattr(module, "basic_data_quality_check"):
                results.append(f"  üìã Found: basic_data_quality_check()")
            if hasattr(module, "DataQualityMonitor"):
                results.append(f"  üìã Found: DataQualityMonitor class")
            if hasattr(module, "simulate_database_metrics"):
                results.append(f"  üìã Found: simulate_database_metrics()")

        except ImportError as e:
            results.append(f"‚ùå {module_name} - Import error: {e}")
        except Exception as e:
            results.append(f"‚ö†Ô∏è  {module_name} - Other error: {e}")

    return results


def test_data_quality_fallback():
    """Test data quality fallback functionality"""
    print("üß™ Testing Data Quality Fallback Functions...")

    results = []

    try:
        sys.path.append("include")
        from utils.data_quality_monitoring import basic_data_quality_check

        # Test function signature (without actual DB connection)
        import inspect

        sig = inspect.signature(basic_data_quality_check)
        params = list(sig.parameters.keys())

        expected_params = ["table_name", "schema_name", "conn_id"]
        if all(param in params for param in expected_params):
            results.append("‚úÖ basic_data_quality_check - Correct function signature")
        else:
            results.append(
                f"‚ùå basic_data_quality_check - Incorrect signature. Expected: {expected_params}, Got: {params}"
            )

    except Exception as e:
        results.append(f"‚ùå basic_data_quality_check test failed: {e}")

    return results


def test_metrics_exporter():
    """Test metrics exporter functionality"""
    print("üìä Testing Metrics Exporter...")

    results = []

    try:
        sys.path.append("include")
        from utils.metrics_exporter import simulate_database_metrics

        results.append("‚úÖ metrics_exporter - Functions accessible")

        # Test if prometheus_client is available (not required for validation)
        try:
            import prometheus_client

            results.append("‚úÖ prometheus_client - Available for metrics")
        except ImportError:
            results.append("‚ö†Ô∏è  prometheus_client - Not installed (optional)")

    except Exception as e:
        results.append(f"‚ùå metrics_exporter test failed: {e}")

    return results


def test_connection_pooling():
    """Test connection pooling utilities"""
    print("üîó Testing Connection Pooling...")

    results = []

    try:
        sys.path.append("include")
        from utils.connection_pooling import DatabaseConnectionPool

        results.append("‚úÖ connection_pooling - DatabaseConnectionPool class found")

        # Check if class has expected methods
        import inspect

        methods = [
            name
            for name, method in inspect.getmembers(
                DatabaseConnectionPool, inspect.isfunction
            )
        ]

        expected_methods = ["get_connection", "close_all_connections"]
        found_methods = [
            m
            for m in expected_methods
            if m in methods
            or f"_DatabaseConnectionPool__{m}" in dir(DatabaseConnectionPool)
        ]

        if (
            len(found_methods) >= len(expected_methods) // 2
        ):  # Allow for some flexibility
            results.append("‚úÖ connection_pooling - Expected methods available")
        else:
            results.append(
                f"‚ö†Ô∏è  connection_pooling - Some methods missing: {expected_methods}"
            )

    except Exception as e:
        results.append(f"‚ùå connection_pooling test failed: {e}")

    return results


def test_configuration_files():
    """Test configuration file validity"""
    print("‚öôÔ∏è Testing Configuration Files...")

    results = []

    config_files = [
        ("airflow_settings.yaml", "YAML"),
        ("docker-compose.yml", "Docker Compose"),
        ("requirements.txt", "Python Requirements"),
        ("config/postgresql.conf", "PostgreSQL Config"),
        ("config/prometheus.yml", "Prometheus Config"),
    ]

    for file_path, file_type in config_files:
        path = Path(file_path)
        if path.exists():
            try:
                content = path.read_text(encoding="utf-8")
                if content.strip():
                    results.append(f"‚úÖ {file_type} - {file_path} (Valid)")
                else:
                    results.append(f"‚ö†Ô∏è  {file_type} - {file_path} (Empty)")
            except Exception as e:
                results.append(f"‚ùå {file_type} - {file_path} (Read error: {e})")
        else:
            results.append(f"‚ö†Ô∏è  {file_type} - {file_path} (Not found)")

    return results


def test_grafana_dashboards():
    """Test Grafana dashboard configurations"""
    print("üìà Testing Grafana Dashboards...")

    results = []

    dashboard_dir = Path("config/grafana/dashboards")
    if dashboard_dir.exists():
        dashboard_files = list(dashboard_dir.glob("*.json"))

        for dashboard_file in dashboard_files:
            try:
                import json

                with open(dashboard_file, "r", encoding="utf-8") as f:
                    dashboard_data = json.load(f)

                # Check for required dashboard fields
                required_fields = ["title", "panels"]
                if all(field in dashboard_data for field in required_fields):
                    results.append(f"‚úÖ Dashboard - {dashboard_file.name} (Valid JSON)")
                else:
                    results.append(
                        f"‚ö†Ô∏è  Dashboard - {dashboard_file.name} (Missing required fields)"
                    )

            except json.JSONDecodeError as e:
                results.append(
                    f"‚ùå Dashboard - {dashboard_file.name} (Invalid JSON: {e})"
                )
            except Exception as e:
                results.append(f"‚ùå Dashboard - {dashboard_file.name} (Error: {e})")
    else:
        results.append("‚ö†Ô∏è  Grafana dashboards directory not found")

    return results


def main():
    """Run all utility and data quality tests"""

    print("üöÄ MetaLayer Utility & Data Quality Validation")
    print("=" * 60)

    all_results = []

    # Run all test functions
    test_functions = [
        test_utility_imports,
        test_data_quality_fallback,
        test_metrics_exporter,
        test_connection_pooling,
        test_configuration_files,
        test_grafana_dashboards,
    ]

    for test_func in test_functions:
        try:
            results = test_func()
            all_results.extend(results)
        except Exception as e:
            all_results.append(f"‚ùå {test_func.__name__} failed: {e}")
            traceback.print_exc()
        print()

    # Summary
    print("üìã VALIDATION SUMMARY")
    print("=" * 60)

    success_count = len([r for r in all_results if r.strip().startswith("‚úÖ")])
    warning_count = len([r for r in all_results if r.strip().startswith("‚ö†Ô∏è")])
    error_count = len([r for r in all_results if r.strip().startswith("‚ùå")])

    for result in all_results:
        print(result)

    print(f"\nüìä RESULTS:")
    print(f"‚úÖ Passed: {success_count}")
    print(f"‚ö†Ô∏è  Warnings: {warning_count}")
    print(f"‚ùå Errors: {error_count}")

    if error_count == 0:
        print(f"\nüéâ All critical tests passed! Utilities are functional.")
        return 0
    else:
        print(f"\nüîß {error_count} errors found. Please review above.")
        return 1


if __name__ == "__main__":
    sys.exit(main())
